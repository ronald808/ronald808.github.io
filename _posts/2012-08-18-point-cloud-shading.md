---
title: Point Cloud Shading
layout: post
---

Data sets generated by range Scanning systems (LiDAR, echosounder, etc.) can be readily displayed as a point cloud. Points are usually colored by depth, range, quality or amplitude for easier interpretation. Point cloud rendering is straight-forward: load point into GPU vertex buffers and use a pixel/fragment shader for coloring. 

This simplicity comes with a drawback: compare to meshed model, point cloud tends to be more difficult to interpret due to incomplete depth perception. Varying the point size based on eye distance helps enhance perspective, but small scale variations are usually hard to distinguish. Shading would help a greatly here (think bump-mapping) but requires us to have normal vectors at each points.

A good way to compute normal vectors is to triangulate the points but this is not always practical. In our case, however, we may be able to estimate normal vector easily.

Our application uses two multibeam echosounders to scan boats sailing overhead. Each sonar generate a 2D-profiles of {range, angles} points several times per second. We measure the ship speed so we can generate a 3D point cloud of the hull from the 2D profiles stack. 

![scan diagram]( /assets/images/hullsweep-diag.png)



In this particular case, we perform a rudimentary triangulation by connecting neighboring points in the along and across ship track directions. The normal vector at each points is then computed as the average of the normal vectors of the adjacent triangles.

So we have the following (unshaded) point cloud:


![no shading]( /assets/images/hullsweep-snap-no-shading.png )


Turn into:

![no shading]( /assets/images/hullsweep-snap-with-shading.png )


One particular spot of interest is the "bump" on the port side of the hull:

<table>
<tr>
<td><img src="/assets/images/hullsweep-snap-no-shading-closeup.png"/></td>
<td><img src="/assets/images/hullsweep-snap-with-shading-closeup.png"/></td>
</tr>
</table>

Even a rudimentary point shading helps in interpreting the data in real-time without reconstructing a fully meshed 3D model of the scene. 

  

     
    
 