---
layout: post
title: "GPU Accelerated Raster Rendering"
---

In this article, we look at optimizing raster rendering in the context of Geographic Information Systems (GIS). These techniques are not restricted to the GIS field and could be applied in any situation where large grids or images need to be rendered efficiently.   
GIS applications typically display many layers of vector graphics, text information and rasters either in 2D or 3D.  While 3D GIS such as Google Earth and ArcScene/ArcGIS rely on hardware acceleration, 2D GIS usually do not. These are many reasons to switch to hardware rendering, since GPU-processing can dramatically accelerate some tasks:

- Temporal analysis, such as vector field animation
- High density data rendering (millions of graphic items)
- Animated symbols, markers and images
- Interactive pixel processing (adjustments such as color-mapping, sun-shading, layer transparency)
- Interactive navigation (click-and-throw or touch-based scrolling, fluid zoom in/out) 
- Mobile device support (for performance reasons, software rendering may not be an option on embedded devices)    

On the downside, GPU rendering is more complex and harder to develop as detailed in my [previous article]({% post_url 2013-07-14-software-vs-hardware-rendering%}) 

![]( {{site.baseurl}}/assets/images/gis-many-layers.jpg)

### GIS Raster Mosaic ###

Rasters are basically n x m arrays of samples which may represent different type of layers in a GIS context. For example:
<code>
<table>
<tr><th>Sample Type</th><th>GIS Layer</th></tr>
<tr><td>8 bit RGBA</td><td>Color Imagery (16M color + transparency)</td></tr>
<tr><td>8 bit</td><td>Greyscale Imagery</td></tr>
<tr><td>32 bit float</td><td>Digital Elevation Model (DEM)</td></tr>
<tr><td>16 bit integer</td><td>High resolution amplitude</td></tr>
<tr><td>{varies} </td><td>Multi-spectral imagery </td></tr>
</table>
</code>

To be meaningful, a raster must be accompanied with geocoding information which defines its real world location. Different rasters may not share the same coordinate system (i.e. that may have been created in different datum/projection) and re-projection may be necessary in order to render them on the same view. The GPU then very efficiently textures the raster on a triangle mesh.

<!--- ![Virtual Texturing]( /assets/images/mesh.png ) -->
<img alt="Virtual Texturing" src="{{site.baseurl}}/assets/images/mesh.png" style="max-width:60%"/>


We also need to be careful about the amount of data we handle. For instance, if we have a 16k color image (16384x16384) to display, a simple (naive) approach would be to load almost 1GB of data when fully zoomed-out. To prevent this, we need to adjust the "resolution" of the raster based on the zoom level of the display viewport. A convenient way to achieve this is to generate a "pyramid" of raster of decreasing resolution by merging four raster samples into one, recursively. So our 16384<sup>2</sup> image becomes a pyramid of 16384<sup>2</sup>, 8192<sup>2</sup>, 4096<sup>2</sup>, ... rasters, also called mipmap.

<!--![level of detail]( /assets/images/lod-all.png ) -->

<table>
<tr>
<td><img src="/assets/images/lod-all.png"  /></td>
<td><img src="/assets/images/pyramid.jpg"/></td>
</tr>
</table>

The rendering logic looks like this:
<code>
1. For the current viewport:
	a. Select the appropriate raster Level-Of-Detail (mipmap) based on viewport resolution
	b. Lookup raster sub-region to be displayed (clipping)
2. Load raster sub-region into a texture (streaming)
3. Generate geo-mesh (triangle strip) in "display" coordinates 
4. draw textured mesh on screen (while applying a color ramp to transform pixel from raster sample type to RGBA)
</code>

### Tiling & Sparse Rasters ###

In applications where sparse rasters are common (i.e. many "no-data" samples), we can optimize memory usage greatly by tiling the raster pyramids. For instance, we can divide our 16384<sup>2</sup> raster into a 64<sup>2</sup> grid of 256<sup>2</sup> tiles.
Any "empty" tiles in our pyramid does not need to be stored, so our dataset becomes more compact. (in the example above, the gain is about 40% on the entire pyramid).

We now need to update the rendering technique to support sparse raster pyramid. At first, we could try a simple approach, suck as painting non-empty tiles independently:
<code>
1. load vertex mesh for a tile
2. load tile pixel data to a texture unit
3. render & repeat for next non-empty tile.
</code> 

There are two problems with this approach: 1) performance will be poor due to many draw calls and shifting textures around, 2) no texture filtering support.


Filtering "interpolates" pixels to improve rendering quality, [bilinear](http://en.wikipedia.org/wiki/Bilinear_filtering) and [trilinar](http://en.wikipedia.org/wiki/Trilinear_filtering) filtering are common filters for imagery-like data.  

In the case of bilinear filtering, we need to sample past the border of a tile into the adjacent tile to create an artifact-free filtering. So for filtering to work, we need to expand our 256<sup>2</sup> tile to 257<sup>2</sup> pixels and duplicate the border from adjacent tiles. 
Unfortunately, this would complicate mipmapping code and GPU performance will suffer from non-power of two sizes.
 
###Virtual Texturing and sparse texture###

One way to address both the performance and the filtering issues is to implement a variation of the virtual texturing technique, and to adapt it to sparse textures. The central idea behind [virtual texturing](http://en.wikipedia.org/wiki/MegaTexture) is to tile a large (abstract) texture, store the tiles into a tile buffer and use an indirection table to reference them. The tile buffer does not have to contain all tiles, but only the tiles visible in the current viewport. Tiles are streamed in and out when the viewport moves, since new parts of the "abstract" texture become visible. 
Tiles may be stored anywhere in the buffer since the indirection table keeps track of their location. 

![Virtual Texturing]( /assets/images/vt-texturing.png )

It is now easy to see how virtual texturing will help optimize sparse texture storage: in our indirection table, all the entries mapping to an empty tile will point to the same "transparent/null" tile in the buffer so we only need to store one empty tile.

{% highlight c %}
// GLSL 1.3	Fragment Shader 
// Virtual Texture coordinate to tile buffer coordinate convertion ( integer math implementation)
void translate2d_i( in ivec2 xy, in sampler2D  vtcTex, out ivec4 gc_p, out ivec2 lc_p ) {
	const ivec2 kTileSize	= ivec2( 256 );
	ivec2 vtcCoord	= xy / kTileSize; 
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	//Assuming index table texel format is 8bit normalized interger (f = i / 255.0) 
	gc_p            = ivec4( texelFetch( vtcTex, vtcCoord, lod ) * 255.0 + 0.5 ); 
	gc_p.xy         *= kTileSize;
	lc_p            = xy % kTileSize;
} 
// texelFecth equivalent function using index texture lookup
vec4 vtTexelFetch( in ivec2 xy, in sampler2D  vtcTex, in sampler2DArray bufferTex ) {
	ivec4 gc; //global coordinates
	ivec2 lc; //local coordinates
	translate2d_i( xy, vtcTex, gc, lc );
	ivec3 xyz = ivec3( gc.x + lc.x, gc.y + lc.y, gc.z );
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	return texelFetch( bufferTex, xyz, lod );
} 
{% endhighlight %}

     
The "standard" virtual texturing implementation has one index table and one buffer per "virtual" texture, but in our case, GIS may have *many* layers so we could be wasting textures resources. At a minimum, we should pack many layers of the same sample type (e.g RGBA, Float, ...) into the same index/buffer pair. If we impose an upper limit on our viewport pixel size (say 4096x2048) we have a maximum index table size of 16x8 tile *per layer* ( for 256<sup>2</sup> pixel tiles). Within a 128<sup>2</sup> index texture, we can fit: 128/16 * 128 / 8 = 128 layers assuming bi-linear filtering. (tri-linear filtering would require a mipmapped index texture, but the reasoning is the same)


### Tile Cache and Tile Streaming ###

When moving the viewport around, new tiles are streamed to the tile buffer and "old" tiles can be evicted. If the viewport moves "slowly", only a few tiles need to be replaced. To reduce I/O, we use a Least Recently Used (LRE) scheme, where we evict the "oldest" tiles to make room for the new tiles.   

![Virtual Texturing]( /assets/images/viewport-moved.png )

To keep our rendering responsive, we stream tiles from disk in a separate thread to avoid I/O operation delay. If a tile is not available yet, we can either:

1. Update the index texture to point to the "empty" tile in the buffer. Once the tile is finally loaded we update the index texture to point to the new tile location
2. Keep lower LOD (level of detail) tiles in the buffer (1 tile cover a large extent) and fallback to them while waiting for the higher LOD to load.

In case the number of tiles required by all the layers exceed the tile buffer capacity, we degrade gracefully by switching entire layers to a lower LOD until the tile quota is met.


 Interestingly, hardware support for sparse / partially resident textures is on the horizon. [AMD already has an OpenGL extension](https://www.opengl.org/registry/specs/AMD/sparse_texture.txt) for this, but wider adoption is needed before we can make the switch.
   








  







