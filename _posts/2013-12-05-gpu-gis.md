---
layout: post
title: "GPU Accelerated Raster Rendering"
---

In this article, we look at optimizing raster rendering in the context of Geographic Information Systems (GIS). These techniques are not restricted to the GIS field and could be applied in any situation where large grids or images need to be rendered efficiently.   
GIS softwares typically display many layers of vector graphics, textual information and rasters either in 2D or 3D.  While 3D GIS such as Google Earth and ArcGis 3D Analyst rely on hardware acceleration, 2D oriented GIS usually do not. These are many good reasons to switch to hardware rendering, however, as GPU computation power offers new and richer ways to visualize data:

- Temporal analysis (vector flow animation,etc)
- High density data rendering (millions of graphic items)
- Animated symbols, markers and images
- Interactive pixel processing (Adjustments such as color-mapping, sun-shading, layer transparency, etc. are immediate)
- Interactive navigation ( click-and-throw or touch-based scrolling, fluid zoom in/out) 
- Mobile device support (software rendering may not be an option an embedded devices for performance reasons)    

On the down side, GPU rendering is more complex and harder to develop as detailed in my [previous article]({% post_url 2013-07-14-software-vs-hardware-rendering%}) 

### GIS Raster Mosaic ###

Rasters are basically n x m arrays of samples which may represent different type of layers in a GIS context. For example:
<code>
<table>
<tr><th>Sample Type</th><th>GIS Layer</th></tr>
<tr><td>8 bit RGBA</td><td>Color Imagery (16M color + transparency)</td></tr>
<tr><td>8 bit</td><td>Greyscale Imagery</td></tr>
<tr><td>32 bit float</td><td>Digital Elevation Model (DEM)</td></tr>
<tr><td>16 bit integer</td><td>High resolution amplitude</td></tr>
<tr><td>{varies} </td><td>Multi-spectral imagery </td></tr>
</table>
</code>

To be meaningful, a raster must be accompanied with geo-coding information which will define its location and coverage on a display. Different rasters may not share the same reference (i.e. that may have been created in different datum/projection) so some re-projection may be necessary before we render them on the same view. At the rendering level we will texture our "projected" raster on a mesh of triangles, at task GPU are extremely efficient at. 

<!--- ![Virtual Texturing]( /assets/images/mesh.png ) -->
<img alt="Virtual Texturing" src="{{site.baseurl}}/assets/images/mesh.png" style="max-width:60%"/>


We also need to be smart about the amount of data we handle. Say we have a 16k color image (16384x16384) to display, a naive approach would require us to load almost 1GB of data when fully zoom-out. Obviously, we need to adjust the "resolution" of the raster based on the zoom level of the display viewport. An convenient way to achieve this is to generate a "pyramid" of raster of decreasing resolution by merging four raster samples into one, recursively. So our 16384<sup>2</sup> image becomes a pyramid of 16384<sup>2</sup>, 8192<sup>2</sup>, 4096<sup>2</sup>, ... rasters, also called mipmap.

<!--![level of detail]( /assets/images/lod-all.png ) -->

<table>
<tr>
<td><img src="/assets/images/lod-all.png"  /></td>
<td><img src="/assets/images/pyramid.jpg"/></td>
</tr>
</table>

To render our raster, we need to:
<code>
1. For the current viewport:
	a. Select the appropriate raster Level-Of-Detail (mipmap) based on viewport resolution
	b. Lookup raster sub-region to be displayed (clipping)
2. Load raster sub-region into a texture (streaming)
3. Generate geo-mesh (triangle strip) in "display" coordinate 
4. draw textured mesh on screen (with pixel transform from raster sample type to RGBA)
</code>

### Tiling & Sparse Rasters ###

In applications where sparse rasters are common (i.e. many "null" samples), we could optimize memory usage greatly by tiling our raster pyramids. For instance, we would divide our 16384<sup>2</sup> raster into a 64<sup>2</sup> grid of 256<sup>2</sup> tiles.
Any "empty" tiles in our pyramid does not need to be stored so our dataset may become more compact. (in the example above, the gain is about 40% on the entire pyramid)

We now need to update our rendering technique to support sparse raster pyramid. At first, we could try something easy; like painting non-empty tiles independently:
<code>
1. load vertex mesh for a tile
2. load tile pixel data to a texture unit
3. render & repeat for next non-empty tile.
</code> 

Two problems with this naive approach: 1) performance will be poor due to many draw calls and shifting textures around, 2) no texture filtering support.


Filtering "interpolates" pixels to improve rendering quality, [bilinear](http://en.wikipedia.org/wiki/Bilinear_filtering) and [trilinar](http://en.wikipedia.org/wiki/Trilinear_filtering) filtering are the most common filters for imagery-like data.  

In the case of bilinear filtering we need to sample past the border of a tile into the adjacent tile to create an artifact-free filtering. So for filtering to work, we need to expand our 256<sup>2</sup> tile to 257<sup>2</sup> pixels and duplicate the border from adjacent tiles. 
Unfortunately, this would complicate mipmapping code and GPU performance will suffer from non-power of two sizes.
 
###Virtual Texturing and sparse texture###

One way to address both the performance and filtering issues is to implement a variation of the virtual texturing technique adapted to sparse texture. The central idea behind [virtual texturing](http://en.wikipedia.org/wiki/MegaTexture) is to tile a large (abstract) texture, store the tiles into a tile buffer and use an indirection table to reference them. The tile buffer does not have to contain all tiles, but only the tiles visible in the current viewport. Tiles are streamed in and out when the viewport move and new part of the "abstract" texture become visible. 
Tiles may be stored anywhere in the buffer since the indirection table keeps track of their location. 

![Virtual Texturing]( /assets/images/vt-texturing.png )

It is now easy to see how virtual texturing will help optimize sparse texture storage: in our indirection table, all entries mapping to an empty tile will point to the same "transparent/null" tile in the buffer so we only need to store one empty tile.

{% highlight c %}
// GLSL 1.3	Fragment Shader 
// Virtual Texture coordinate to tile buffer coordinate convertion ( integer math implementation)
void translate2d_i( in ivec2 xy, in sampler2D  vtcTex, out ivec4 gc_p, out ivec2 lc_p ) {
	const ivec2 kTileSize	= ivec2( 256 );
	ivec2 vtcCoord	= xy / kTileSize; 
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	//Assuming index table texel format is 8bit normalized interger (f = i / 255.0) 
	gc_p            = ivec4( texelFetch( vtcTex, vtcCoord, lod ) * 255.0 + 0.5 ); 
	gc_p.xy         *= kTileSize;
	lc_p            = xy % kTileSize;
} 
// texelFecth equivalent function using index texture lookup
vec4 vtTexelFetch( in ivec2 xy, in sampler2D  vtcTex, in sampler2DArray bufferTex ) {
	ivec4 gc; //global coordinates
	ivec2 lc; //local coordinates
	translate2d_i( xy, vtcTex, gc, lc );
	ivec3 xyz = ivec3( gc.x + lc.x, gc.y + lc.y, gc.z );
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	return texelFetch( bufferTex, xyz, lod );
} 
{% endhighlight %}

     
The "standard" virtual texturing implementation has one index table and one buffer per "virtual" texture, but in our case, GIS may have *many* layers so we could be wasting textures resources. At a minimum, we should pack many layers of the same sample type (e.g RGBA, Float, ...) into the same index/buffer pair. If we impose an upper limit on our viewport pixel size (say 4096x2048) we have a maximum index table size of 16x8 tile *per layer* ( for 256<sup>2</sup> pixel tiles). Within a 128<sup>2</sup> index texture, we can fit: 128/16 * 128 / 8 = 128 layers assuming bi-linear filtering. (tri-linear filtering would require a mipmapped index texture , but the reasoning is the same)


### Tile Cache and Tile Streaming ###

When moving the viewport, new tiles should be streamed to the tile buffer and "old" tiles should be evicted. If the viewport moves "slowly" only a few tiles need to be replaced. To reduce I/O, we implement a Least Recently Used (LRE) scheme where we evict the "oldest" tiles to make room for the new tiles.   

![Virtual Texturing]( /assets/images/viewport-moved.png )

To keep our rendering responsive, we should stream tiles from disk in a separate thread to avoid I/O operation delay. If a tile is not available yet, we may either:

1. Update the index texture to point to the "empty" tile in the buffer. Once the tile is finally loaded we update the index texture to point to the new tile location
2. Keep lower lod tiles in the buffer (1 tile cover a large extent) and fallback to them while waiting for the higher lod to load.

In case the number of tiles required by all the layers exceed the tile buffer capacity, we can degrade gracefully by switching entire layers to a lower LOD until the tile quota is met.


 Interestingly, some hardware support for sparse / partially resident texture may be on the horizon. [AMD already has an OpenGL extension](https://www.opengl.org/registry/specs/AMD/sparse_texture.txt) for it but wider adoption will be needed before we can make the switch.
   








  







