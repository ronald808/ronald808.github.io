---
layout: post
title: "Accelerating Raster rendering"
---

Front-ends of Geographical Information System (GPU) are in charge of drawing many layers of vector graphics, textual information and raster images. While 3D GIS (e.g. Google Earth, ArcGis 3D Analyst, etc.) have been using graphical processing unit (GPU) to accelerate rendering, 2D oriented GIS could benefit from hardware acceleration as well.
The main motivation behind GPU accelated 2D rendering is to create new visualization techniques which may be to intensive for software renderer. A few examples are:

<div align="center">
<img src="/assets/images/pyramid.jpg" width="350"/>
</div>

- temporal analysis (vector flow, propagation,etc)
- High density data rendering (millions of graphical items)
- Animations (animated symbols, markers, images, etc.)
- Interactive pixel processing (Adjustments such as color-mapping, sun-shading, layer transparency, etc. are immediate)
- Interactive navigation ( click-and-throw or touch-based scrolling, fluid zoom in/out) 
- Mobile device support (software rendering is usually not an option for embedded devices)    


### Software vs. Hardware  ###

So why is software rendering still the approach of choice?. Basically it come to two things: cost and hardware support. Developing a GPU accelerated renderer is much more expensive and complex. Also, if you want you application to run on a wide variety of computer, you'll probably need a software path anyway. Intel's x86 architure is both ubiquitous and backward compatible so your software renderer will run everywhere and create the same output. 

Not so for GPU. 

With three GPU vendors left (NVidia, AMD, Intel), several APIs (D3D, OpenGL, OpenGL ES, OpenCL, Direct2D, etc.) and a long list of GPU drivers bugs to navigate, writing an accelerated GIS renderer targeting a broad user base is not as straight-forward as it should be.

A good illustration of this chaotic situation is WebGL support in Google Chrome web browser: in order to get consistent result for a "mainstream" application like Chrome for Windows, Google had to develop [Angle](https://code.google.com/p/angleproject/) to translate OpenGL ES API calls to Direct9D 9 (OpenGL ES driver may not installed on many Windows machine). In addition, Chrome -[just like FireFox]("https://wiki.mozilla.org/Blocklisting/Blocked_Graphics_Drivers")- maintains a blacklist of broken video drivers to gracefully disable hardware acceleration if a buggy driver is spotted...

### Mainstream GPU ###

For user to benefit from accelerated code, they need a GPU and this is where the advent of CPU integrated GPU have changed everything. No need for a discrete graphics card: if your own a recent x86 computer, you have a good-enough GPU that can be used for GIS tasks.  

### GIS Raster Mosaic ###

Rasters are basically n x m arrays of sample which may represent different type of layers in a GIS context. For example:

<table>
<tr><th>Sample Type</th><th>GIS Layer</th></tr>
<tr><td>8 bit RGBA</td><td>Color Imagery (16M color + transparency)</td></tr>
<tr><td>8 bit</td><td>Greyscale Imagery</td></tr>
<tr><td>32 bit float</td><td>Digital Elevation Model</td></tr>
<tr><td>16 bit integer</td><td>High resolution amplitude</td></tr>
<tr><td>{varies} </td><td>Multi-spectral imagery </td></tr>
</table>

To be meaningful, a raster must be accompanied with geo-coding information which will define its location and coverage on the display. All rasters loaded in a GIS view may not share the same reference (i.e. that may have been created in different datum/projection) so some re-projection may have to take place before we render them. At the rendering level we will texture our "projected" raster on a mesh of triangles, at task GPU are extremely efficient at. 

![Virtual Texturing]( /assets/images/mesh.png )

We also need to smart about the amount of data we handle. Say we have a 16k color image (16384x16384) to display, a naive approach would require us to load almost 1GB of data when fully zoom-out. Obviously, we need to adjust the "resolution" of the raster based on the zoom level of the display viewport. An convenient way to achieve this is to generate a "pyramid" of raster of decreasing resolution by merging four raster samples into one, recursively. So our 16384<sup>2</sup> image becomes a pyramid of 16384<sup>2</sup>, 8192<sup>2</sup>, 4096<sup>2</sup>, ... rasters, also called mipmap.

![level of detail]( /assets/images/lod-all.png )

So now our rendering tasks would be:

1. Based on current viewport:
	1. Select the proper raster Level-Of-Detail (mipmap)
	2. Lookup raster sub-region to be displayed
2. Load raster sub-region into a texture (streaming)
2. Generate geo-mesh (triangle strip) in "display" coordinate 
4. draw textured mesh on screen (with pixel transform from raster sample type to RGBA)


### Tiling & Sparse Rasters ###

In applications where sparse raster are common (i.e. many "null" samples), we could optimize things greatly by tiling our raster pyramids. For instance, we would divide our 16384<sup>2</sup> raster into a 64<sup>2</sup> grid of 256<sup>2</sup> tiles.
Any "empty" tile at any mipmap level does not need to be stored so our dataset may become more compact. (in the example above, the gain is about 40% on the whole pyramid)

We now have update our rendering technique to support sparse mips pyramid so we can save on GPU memory. At first, we could try something easy: we just paint   non-empty tiles independently:

-  load vertex mesh for a tile
-  load tile pixels to texture unit
-  render & repeat for next non-empty tile. 


Two problems with this: 

- Poor performances: many draw calls and shifting textures around
- No filtering support

Filtering "interpolates" pixels to improve rendering quality, bilinear and trilinar filtering are the most common filters for imagery-like data.  

In the case of bilinear filtering we need to sample past the border of a tile into the adjacent tile to create an artifact-free filtering. So for filtering to work, we need to expand our 256<sup>2</sup> tile to 257<sup>2</sup> pixels and duplicate the border from adjacent tiles. 
Unfortunately, we would now have non-power of two tiles and more complicated mipmapping and tiles maintenance code. 
 
###Virtual Texturing and sparse texture###

One way to address both the performance and filtering issue is to implement a variation of the virtual texturing technique adapted to sparse texture. The central idea behind virtual texturing is to tile an abstract large texture  and use an indirection referencing each tiles location in a separate tile buffer. The tile buffer doesn't have to contain all tiles, but only the tiles visible in the current viewport. Tiles are streamed in and out when the viewport move and new part of the "abstract" texture become visible. 
Tiles may be stored anywhere in the buffer since the indirection table keeps track of their location. 

![Virtual Texturing]( /assets/images/vt-texturing.png )

It is now easy to see how virtual texturing will help optimize sparse texture storage: in our indirection table, all empty tiles index will point to the same "transparent/null" tile in the buffer so we only need to store one empty tile.

{% highlight c %}
// GLSL 1.3	Fragment Shader 
// Virtual Texture coordinate to tile buffer coordinate convertion ( integer math implementation)
void translate2d_i( in ivec2 xy, in sampler2D  vtcTex, out ivec4 gc_p, out ivec2 lc_p ) {
	const ivec2 kTileSize	= ivec2( 256 );
	ivec2 vtcCoord	= xy / kTileSize; 
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	//Assuming index table texel format is 8bit normalized interger (f = i / 255.0) 
	gc_p			= ivec4( texelFetch( vtcTex, vtcCoord, lod ) * 255.0 + 0.5 ); 
	gc_p.xy			*= kTileSize;
	lc_p			= xy % kTileSize;
} 
// texelFecth equivalent function using index texture lookup
vec4 myTexelFetch( in ivec2 xy, in sampler2D  vtcTex, in sampler2DArray bufferTex ) {
	ivec4 gc;
	ivec2 lc;
	translate2d_i( xy, vtcTex, gc, lc );
	ivec3 xyz = ivec3( gc.x + lc.x, gc.y + lc.y, gc.z );
	// LOD would be needed for tri-lin filtering or lower-lod fall back:
	const int lod   =0;
	return texelFetch( bufferTex, xyz, lod );
} 
{% endhighlight %}

     
The "standard" virtual texturing implementation has one index table and one buffer per "virtual" texture, but in our case, GIS may have *many* layers so we could be wasting textures resources. At a minimum, we should pack many layers of the same sample type (e.g RGBA, float, ...) into the same index/buffer pair. If we impose an upper limit to our viewport in pixel (say 4096x2048) we have a maximum index table size of 16x8 tile *per layer* ( for 256<sup>2</sup> pixel tiles). Within a 128<sup>2</sup> index texture, we can fit: 128/16 * 128 / 8 = 128 layers assuming bi-linear filtering. (tri-linear filtering would require a   mipmapped index texture , but the reasoning is the same)


### Tile Cache and Tile Streaming ###

When moving the viewport, new tiles should be streamed to the tile buffer and "old" tile should be evicted. If the viewport moves "slowly" only a few tiles need to be replaced. To reduce I/O, we implement a Least Recently Used (LRE) tile cache management system where we evict the "oldest" tiles to make room for the new tiles.   

![Virtual Texturing]( /assets/images/viewport-moved.png )

To keep our rendering responsive, we should stream tiles from disk in a separate thread to avoid I/O operation delay. If a tile is not yet available we may either:

1. Update the index texture to point to the "empty" tile in the buffer. Once the tile is finally loaded we update the index texture to point to the new tile location
2. Keep lower lod tiles in the buffer (1 tile cover a large extent) and fallback to them while waiting for the higher lod to load.

In case the number of tile required by all the layers exceed the tile buffer capacity, we can degrade gracefully by switching entire layers to a lower LOD until the tile quota is met.


 Interestingly, some hardware support for sparse / partially resident texture may be on the horizon. [AMD already has an OpenGL extension](https://www.opengl.org/registry/specs/AMD/sparse_texture.txt) for it but wider adoption will be needed before we can make the switch.
   
 




  
   








  







